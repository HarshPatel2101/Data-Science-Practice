{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Harsh\n",
      "[nltk_data]     Patel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Libraries Needed For NLTK\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "#Libraries For Tenserflow Processing\n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import random \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our Chat-bot intents file\n",
    "with open('intents.json') as json_data:\n",
    "    intents = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intents': [{'tag': 'greeting',\n",
       "   'patterns': ['Hi', 'How are you', 'Is anyone there?', 'Hello', 'Good day'],\n",
       "   'responses': ['Hello, thanks for visiting',\n",
       "    'Good to see you again',\n",
       "    'Hi there, how can I help?'],\n",
       "   'context_set': ''},\n",
       "  {'tag': 'goodbye',\n",
       "   'patterns': ['Bye', 'See you later', 'Goodbye'],\n",
       "   'responses': ['See you later, thanks for visiting',\n",
       "    'Have a nice day',\n",
       "    'Bye! Come back again soon.']},\n",
       "  {'tag': 'thanks',\n",
       "   'patterns': ['Thanks', 'Thank you', \"That's helpful\"],\n",
       "   'responses': ['Happy to help!', 'Any time!', 'My pleasure']},\n",
       "  {'tag': 'chatbot',\n",
       "   'patterns': ['Who built this chatbot?',\n",
       "    'Tell me about Chatbot',\n",
       "    'What is this chatbot name?'],\n",
       "   'responses': ['Hi, I am Chatbot designed by Mayank.',\n",
       "    'Thanks for asking. I am designed by Mayank Bajaj.',\n",
       "    'I am a chatbot.']},\n",
       "  {'tag': 'location',\n",
       "   'patterns': ['What is your location?',\n",
       "    'Where are you located?',\n",
       "    'What is your address?'],\n",
       "   'responses': [\"We are from World's largest Democracy India.\",\n",
       "    'You can visit India to meet us',\n",
       "    'Thans for your Interest. I live in India.']},\n",
       "  {'tag': 'connect',\n",
       "   'patterns': ['Give me your social media accounts link',\n",
       "    'Where can we connect',\n",
       "    'How can i reach out to you?',\n",
       "    'Is there any way we can connect'],\n",
       "   'responses': ['You can connect me on Linkedin or Github \\n Linkedin - https://www.linkedin.com/in/mayank-bajaj/ \\n Github - https://github.com/mayank8200',\n",
       "    'You can visit https://mayank-bajaj.me']},\n",
       "  {'tag': 'movies',\n",
       "   'patterns': ['Which is your favourite movie?',\n",
       "    'Suggest me some movies',\n",
       "    'Recommend movies'],\n",
       "   'responses': ['3 idiots',\n",
       "    'Hera Pheri',\n",
       "    'Lage Raho Munna Bhai',\n",
       "    'OMG: Oh My God!',\n",
       "    'PK',\n",
       "    'Yeh Jawani hai Deewani',\n",
       "    'Zindagi na Milegi Doobara',\n",
       "    'Ludo']},\n",
       "  {'tag': 'about',\n",
       "   'patterns': ['Who are you?', 'Tell me about Yourself', 'What is this?'],\n",
       "   'responses': ['Hi, I am Mayank. Nice to meet you. I made this chatbot for fun and practice.',\n",
       "    'Thanks for asking. I am Mayank Bajaj, coder by profession but ML enthusiast by passion.']}]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore = ['?']\n",
    "\n",
    "# Loop through each intent in the intents\n",
    "for intent in intents['intents']:\n",
    "    # Loop through each sentence pattern in the current intent\n",
    "    for pattern in intent['patterns']:\n",
    "        # Tokenize each word in the sentence pattern\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        \n",
    "        # Add words to the word list\n",
    "        words.extend(w)\n",
    "        \n",
    "        # Add words and their corresponding intent tag to the documents\n",
    "        documents.append((w, intent['tag']))\n",
    "        \n",
    "        # Add the intent tag to the classes list if not already present\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 documents\n",
      "8 classes ['about', 'chatbot', 'connect', 'goodbye', 'greeting', 'location', 'movies', 'thanks']\n",
      "8 unique stemmed words ['about', 'chatbot', 'connect', 'goodbye', 'greeting', 'location', 'movies', 'thanks']\n"
     ]
    }
   ],
   "source": [
    "# Perform stemming and lower each word as well as remove duplicates\n",
    "\n",
    "from enum import unique\n",
    "\n",
    "\n",
    "words = [stemmer.stem(w.lower()) for w in words if w not in ignore]\n",
    "words = sorted(list(set(classes)))\n",
    "\n",
    "#remove duplicate classes\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "print(len(documents), \"documents\")\n",
    "print(len(classes) ,'classes' , classes)\n",
    "print(len(words) , 'unique stemmed words',words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training Data\n",
    "training =[]\n",
    "output = []\n",
    "\n",
    "#create an empty array for output\n",
    "output_empty = [0]*len(classes)\n",
    "\n",
    "#create training set,bag of words for each sentence\n",
    "for doc in documents:\n",
    "    #initialize bag of words\n",
    "    bag=[]\n",
    "    #list of tokenized words for the pattern\n",
    "    pattern_words = doc[0]\n",
    "    # streaming each words\n",
    "    pattern_words= [stemmer.stem(word.lower()) for word in pattern_words]\n",
    "    #create bag of words array\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "\n",
    "    #output is '1' for current tag and '0' for rest of other tags\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "\n",
    "    training.append([bag,output_row])\n",
    "\n",
    "# shuffling features and turning it into np.array\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "\n",
    "# creating training list\n",
    "\n",
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(10 , input_shape = (len(train_x[0]),)))\n",
    "model.add(tf.keras.layers.Dense(10))\n",
    "model.add(tf.keras.layers.Dense(len(train_y[0]), activation = 'softmax'))\n",
    "model.compile(tf.keras.optimizers.Adam() , loss='categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 2s 14ms/step - loss: 2.0928 - accuracy: 0.0741\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0883 - accuracy: 0.1852\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 2.0837 - accuracy: 0.1852\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0804 - accuracy: 0.1852\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0764 - accuracy: 0.1852\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 2.0727 - accuracy: 0.1852\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.0684 - accuracy: 0.2593\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0649 - accuracy: 0.2593\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0618 - accuracy: 0.2593\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.0574 - accuracy: 0.2593\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.0540 - accuracy: 0.2593\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0504 - accuracy: 0.2593\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0472 - accuracy: 0.2593\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 2.0434 - accuracy: 0.2593\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0399 - accuracy: 0.2593\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0367 - accuracy: 0.2593\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0332 - accuracy: 0.2593\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0299 - accuracy: 0.2593\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0263 - accuracy: 0.2593\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 2.0232 - accuracy: 0.2593\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0194 - accuracy: 0.2593\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0167 - accuracy: 0.2593\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.0126 - accuracy: 0.2593\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.0089 - accuracy: 0.2593\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 2.0055 - accuracy: 0.2593\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0016 - accuracy: 0.2593\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.9987 - accuracy: 0.2593\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.9952 - accuracy: 0.3333\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9915 - accuracy: 0.3333\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.9878 - accuracy: 0.3333\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.9848 - accuracy: 0.3333\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.9811 - accuracy: 0.3333\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.9782 - accuracy: 0.3333\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.9747 - accuracy: 0.3333\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.9716 - accuracy: 0.3333\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.9685 - accuracy: 0.3333\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9647 - accuracy: 0.3333\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.9623 - accuracy: 0.3333\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.9587 - accuracy: 0.3333\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.9547 - accuracy: 0.3333\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.9518 - accuracy: 0.3333\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.9480 - accuracy: 0.3333\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.9449 - accuracy: 0.3333\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.9407 - accuracy: 0.3333\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9378 - accuracy: 0.3333\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.9333 - accuracy: 0.3333\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.9295 - accuracy: 0.3333\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.9258 - accuracy: 0.3333\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.9220 - accuracy: 0.3333\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.9178 - accuracy: 0.3333\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.9143 - accuracy: 0.3704\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.9098 - accuracy: 0.3704\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.9066 - accuracy: 0.3704\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.9024 - accuracy: 0.3704\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.8981 - accuracy: 0.3704\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.8952 - accuracy: 0.3704\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.8903 - accuracy: 0.3704\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8877 - accuracy: 0.3704\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.8832 - accuracy: 0.3704\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8797 - accuracy: 0.3704\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.8759 - accuracy: 0.3704\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.8723 - accuracy: 0.3704\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.8680 - accuracy: 0.3704\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8652 - accuracy: 0.3704\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8608 - accuracy: 0.3704\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8573 - accuracy: 0.3704\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8538 - accuracy: 0.3704\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.8499 - accuracy: 0.3704\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.8459 - accuracy: 0.3704\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.8431 - accuracy: 0.3704\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.8387 - accuracy: 0.3704\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.8357 - accuracy: 0.3704\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.8318 - accuracy: 0.3704\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8285 - accuracy: 0.3704\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.8247 - accuracy: 0.3704\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.8215 - accuracy: 0.3704\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8174 - accuracy: 0.3704\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.8143 - accuracy: 0.3704\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.8106 - accuracy: 0.3704\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.8066 - accuracy: 0.3704\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.8029 - accuracy: 0.3704\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.7995 - accuracy: 0.3704\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.7955 - accuracy: 0.3704\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.7924 - accuracy: 0.3704\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.7883 - accuracy: 0.3704\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.7844 - accuracy: 0.3704\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7816 - accuracy: 0.3704\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.7778 - accuracy: 0.3704\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.7738 - accuracy: 0.3704\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.7711 - accuracy: 0.3704\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.7673 - accuracy: 0.3704\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.7638 - accuracy: 0.4074\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7611 - accuracy: 0.4074\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.7573 - accuracy: 0.4074\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.7539 - accuracy: 0.4074\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.7509 - accuracy: 0.4074\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.7473 - accuracy: 0.4074\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7442 - accuracy: 0.4074\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.7410 - accuracy: 0.4074\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.7380 - accuracy: 0.4074\n",
      "INFO:tensorflow:Assets written to: model.api\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.api\\assets\n"
     ]
    }
   ],
   "source": [
    "model.fit(np.array(train_x) , np.array(train_y) , epochs=100 , batch_size = 20 ,verbose=1)\n",
    "model.save(\"model.api\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
